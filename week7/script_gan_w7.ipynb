{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 1\n",
    "\n",
    "Note: Carefully revisit the reading material, and choose additional sources if needed.\n",
    "\n",
    "- a. Briefly explain why the Generatorâ€™s loss function only depends on the Discriminator's output for generated images. (Note: different representations.)\n",
    "\n",
    "- b. What is â€œmode collapseâ€ in GANs? Provide an intuitive example of how it might appear when generating images, and explain one strategy (theoretical or architectural) that can mitigate it. Provide a reference (from the provided reading material or beyond).\n",
    "\n",
    "- c. What is the difference between Inception Score (IS) and FrÃ©chet Inception Distance (FID)?\n",
    "\n",
    "- d. Choose one application of GANs, and discuss potential ethical issue(s) that could arise.\n",
    "\n",
    "\n",
    "\n",
    "potential answers:\n",
    "\n",
    "\n",
    "\n",
    "Task 1: Theory - GAN background\n",
    "a. Generator's Loss Function Dependency\n",
    "The generator's loss function only depends on the discriminator's output for generated images because:\n",
    "\n",
    "The generator's objective is to fool the discriminator into classifying fake images as real\n",
    "\n",
    "During generator training, we freeze the discriminator and only update generator parameters\n",
    "\n",
    "The loss is calculated as: L_G = -log(D(G(z))) where we want D(G(z)) â†’ 1 (real)\n",
    "\n",
    "We don't use real images in generator loss because the generator doesn't need to learn from real data directly - it learns indirectly through the discriminator's feedback\n",
    "\n",
    "b. Mode Collapse\n",
    "Definition: Mode collapse occurs when the generator produces limited varieties of samples, capturing only a few modes of the data distribution while ignoring others.\n",
    "\n",
    "Intuitive Example: When generating human faces, a GAN suffering from mode collapse might only generate faces of middle-aged Caucasian males, ignoring other ethnicities, ages, and genders.\n",
    "\n",
    "Mitigation Strategy: Mini-batch Discrimination (proposed in Improved GANs by Salimans et al.)\n",
    "\n",
    "The discriminator looks at multiple samples in a batch to detect if the generator is producing similar outputs\n",
    "\n",
    "This allows the discriminator to penalize lack of diversity\n",
    "\n",
    "Reference: Salimans, T., et al. \"Improved techniques for training gans.\" NeurIPS 2016.\n",
    "\n",
    "c. IS vs FID Comparison\n",
    "Inception Score (IS):\n",
    "\n",
    "Measures quality and diversity using pre-trained Inception network\n",
    "\n",
    "High score when: high confidence in predictions (quality) and diverse predictions across samples (diversity)\n",
    "\n",
    "Only uses generated images\n",
    "\n",
    "FrÃ©chet Inception Distance (FID):\n",
    "\n",
    "Compares statistics of real and generated images in feature space\n",
    "\n",
    "Lower FID = better quality and diversity\n",
    "\n",
    "Uses both real and generated images\n",
    "\n",
    "Generally considered more reliable than IS\n",
    "\n",
    "d. Ethical Issues in GAN Applications\n",
    "Application: Deepfake generation for entertainment/media\n",
    "\n",
    "Ethical Issues:\n",
    "\n",
    "Identity theft and impersonation: Creating convincing fake videos of public figures\n",
    "\n",
    "Non-consensual pornography: Generating explicit content using people's likeness without consent\n",
    "\n",
    "Misinformation: Creating fake news or events that never happened\n",
    "\n",
    "Legal evidence tampering: Potential to undermine trust in video evidence\n",
    "\n",
    "\n",
    "\n",
    "another potential answer\n",
    "\n",
    "\n",
    "ğŸ§  Task 1 â€” Theory\n",
    "a. Why the Generatorâ€™s loss depends only on the Discriminatorâ€™s output for generated images\n",
    "\n",
    "The generator never sees real data; it only receives feedback through the discriminator.\n",
    "Formally,\n",
    "\n",
    "min\n",
    "â¡\n",
    "ğº\n",
    "ğ¸\n",
    "ğ‘§\n",
    "âˆ¼\n",
    "ğ‘\n",
    "ğ‘§\n",
    "[\n",
    "log\n",
    "â¡\n",
    "(\n",
    "1\n",
    "âˆ’\n",
    "ğ·\n",
    "(\n",
    "ğº\n",
    "(\n",
    "ğ‘§\n",
    ")\n",
    ")\n",
    ")\n",
    "]\n",
    "G\n",
    "min\n",
    "\tâ€‹\n",
    "\n",
    "E\n",
    "zâˆ¼p\n",
    "z\n",
    "\tâ€‹\n",
    "\n",
    "\tâ€‹\n",
    "\n",
    "[log(1âˆ’D(G(z)))]\n",
    "\n",
    "The generator adjusts its parameters Î¸áµ so that D(G(z)) â†’ 1 (i.e., fake â†’ real).\n",
    "Hence the loss depends only on D(G(z)) â€” the discriminatorâ€™s evaluation of generated samples.\n",
    "All gradient information about realism flows through that scalar output; the generatorâ€™s job is simply to make D believe its samples are real.\n",
    "\n",
    "Alternative â€œnon-saturatingâ€ form\n",
    "\n",
    "max\n",
    "â¡\n",
    "ğº\n",
    "ğ¸\n",
    "ğ‘§\n",
    "âˆ¼\n",
    "ğ‘\n",
    "ğ‘§\n",
    "[\n",
    "log\n",
    "â¡\n",
    "ğ·\n",
    "(\n",
    "ğº\n",
    "(\n",
    "ğ‘§\n",
    ")\n",
    ")\n",
    "]\n",
    "G\n",
    "max\n",
    "\tâ€‹\n",
    "\n",
    "E\n",
    "zâˆ¼p\n",
    "z\n",
    "\tâ€‹\n",
    "\n",
    "\tâ€‹\n",
    "\n",
    "[logD(G(z))]\n",
    "\n",
    "This avoids vanishing gradients early in training but still depends solely on D(G(z)).\n",
    "\n",
    "b. Mode Collapse\n",
    "\n",
    "Definition:\n",
    "Mode collapse happens when the generator produces limited diversity â€” e.g., it discovers a few patterns that reliably fool the discriminator and repeats them.\n",
    "\n",
    "Example:\n",
    "In CIFAR-10 training, instead of generating ten diverse object classes, G outputs only one convincing â€œcar-likeâ€ image with small variations.\n",
    "\n",
    "Mitigation strategies\n",
    "\n",
    "Architectural: Use Minibatch Discrimination (Salimans et al., 2016) â†’ D looks at feature diversity across a batch.\n",
    "\n",
    "Objective modification: Wasserstein GAN with Gradient Penalty (WGAN-GP; Gulrajani et al., 2017) stabilizes training and discourages collapse by providing smooth, meaningful gradients.\n",
    "\n",
    "Training trick: Label smoothing, noise injection, or unrolling the discriminator.\n",
    "\n",
    "Reference:\n",
    "Gulrajani et al., â€œImproved Training of Wasserstein GANs,â€ NIPS 2017.\n",
    "\n",
    "c. Inception Score (IS) vs FrÃ©chet Inception Distance (FID)\n",
    "Metric\tWhat it measures\tComputation\tLimitations\n",
    "IS\tImage quality + diversity based on Inception-v3 classifier outputs\t( \\exp(\\mathbb{E}_x [ KL(p(y\tx)\n",
    "FID\tHow close generated images are to real ones in feature space\tComputes FrÃ©chet distance between multivariate Gaussians fitted to Inception features of real vs fake images\tMore robust, penalizes mode collapse and bad diversity\n",
    "âœ… FID < better â‡’ closer to real distribution.\n",
    "d. Application + Ethical Issues\n",
    "\n",
    "Example Application: Face generation / deepfakes\n",
    "\n",
    "Ethical concerns:\n",
    "\n",
    "Misinformation â†’ fake videos or portraits used for fraud or defamation.\n",
    "\n",
    "Consent â†’ use of peopleâ€™s faces without permission.\n",
    "\n",
    "Bias â†’ training on imbalanced datasets amplifies societal biases.\n",
    "\n",
    "Mitigations: Watermarking, detectable synthetic data tags, ethics review for dataset use.\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 2\n",
    "\n",
    "Training a GAN can be challenging. In this exercise we invite you to try it for yourself, and see if you can succeed. We provide a sample notebook, which you can use as a starting point. You probably need to download some data first.\n",
    "\n",
    "Please note: In the provided sample notebook script_gan.ipynb, we use CIFAR10. You are free to use another dataset, MNIST or celebA. You might find it helpful to read more about the pytorch dataloader.\n",
    "\n",
    "Note: Remember to change the data path in the notebook.\n",
    "\n",
    "- a. Complete the notebook by adding the implementation for the generator and discriminator.\n",
    "- b. Which parts of the notebook have to be changed if you want to use another dataset? How do you need to change them?\n",
    "- c. Please document your findings when executing the notebook. Did your training converge? How did the intermediate generated images look like?\n",
    "- d. Name several things which can be changed to receive a different result after training.\n",
    "- e. Choose something to change, e.g. setting, preprocessing or parameters, and run the notebook (at least) 2 more times with different configurations. Save your results. Did the training converge? How do the generated images look like? How do the three different models perform in comparison?\n",
    "Non-mandatory: Comment on your suggestions to change the code."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T10:23:35.900172Z",
     "start_time": "2025-10-18T10:23:33.672248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T10:35:23.922780Z",
     "start_time": "2025-10-18T10:35:23.914499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a simple generator and discriminator for CIFAR-10\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 8 * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (128, 8, 8)),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128, momentum=0.78),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64, momentum=0.78),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Fixed: use self.model not self.fc\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ZeroPad2d((0, 1, 0, 1)),\n",
    "            nn.BatchNorm2d(64, momentum=0.82),\n",
    "            nn.LeakyReLU(0.25),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128, momentum=0.82),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256, momentum=0.8),\n",
    "            nn.LeakyReLU(0.25),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 5 * 5, 1),  # Fixed: calculated correct dimensions\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T10:29:01.955429Z",
     "start_time": "2025-10-18T10:28:44.441047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data loading and preprocessing (using CIFAR-10 dataset)\n",
    "\n",
    "# train on GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "\n",
    "print(f'Train: {len(dataset)} samples')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:14<00:00, 11.8MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 50000 samples\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T10:36:34.343425Z",
     "start_time": "2025-10-18T10:36:34.301912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the models\n",
    "\n",
    "latent_dim = 100\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "num_epochs = 10\n",
    "\n",
    "generator = Generator(latent_dim)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "\n",
    "\n",
    "# Define loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# Lists to store losses for plotting\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "# def train_gan(generator, discriminator, dataloader, num_epochs):\n",
    "#     for epoch in range(num_epochs):\n",
    "#         for i, data in enumerate(dataloader):\n",
    "#             real_images, _ = data\n",
    "#             batch_size = real_images.size(0)\n",
    "#             real_images = real_images.view(batch_size, -1)\n",
    "#             real_labels = torch.ones(batch_size, 1)\n",
    "#             fake_labels = torch.zeros(batch_size, 1)\n",
    "#\n",
    "#             # Train the discriminator\n",
    "#             optimizer_D.zero_grad()\n",
    "#             outputs = discriminator(real_images)\n",
    "#             d_loss_real = criterion(outputs, real_labels)\n",
    "#             d_loss_real.backward()\n",
    "#\n",
    "#             z = torch.randn(batch_size, 100)\n",
    "#             fake_images = generator(z)\n",
    "#             outputs = discriminator(fake_images.detach())\n",
    "#             d_loss_fake = criterion(outputs, fake_labels)\n",
    "#             d_loss_fake.backward()\n",
    "#             d_loss = d_loss_real + d_loss_fake\n",
    "#             optimizer_D.step()\n",
    "#\n",
    "#             # Train the generator\n",
    "#             optimizer_G.zero_grad()\n",
    "#             outputs = discriminator(fake_images)\n",
    "#             g_loss = criterion(outputs, real_labels)\n",
    "#             g_loss.backward()\n",
    "#             optimizer_G.step()\n",
    "#\n",
    "#             d_losses.append(d_loss.item())\n",
    "#             g_losses.append(g_loss.item())\n",
    "#\n",
    "#             if (i + 1) % 100 == 0:\n",
    "#                 print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "#\n",
    "#         # Generate and save a sample of fake images\n",
    "#         if (epoch + 1) % 10 == 0:\n",
    "#             with torch.no_grad():\n",
    "#                 z = torch.randn(32, 100)\n",
    "#                 fake_samples = generator(z)\n",
    "#                 vutils.save_image(fake_samples, f'fake_cifar_samples_epoch_{epoch+1}.png', normalize=True)\n",
    "#\n",
    "#         # Plot the loss curves\n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         plt.title(\"Generator and Discriminator Loss\")\n",
    "#         plt.plot(g_losses, label=\"G Loss\")\n",
    "#         plt.plot(d_losses, label=\"D Loss\")\n",
    "#         plt.xlabel(\"Iterations\")\n",
    "#         plt.ylabel(\"Loss\")\n",
    "#         plt.legend()\n",
    "#         plt.savefig(f'loss_plot_epoch_{epoch+1}.png')\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train_gan(generator, discriminator, dataloader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(dataloader):\n",
    "            real_images, _ = data\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            # Move to same device as models\n",
    "            device = next(generator.parameters()).device\n",
    "            real_images = real_images.to(device)\n",
    "\n",
    "            real_labels = torch.ones(batch_size, 1, device=device)\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "\n",
    "            # Train the discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Real images\n",
    "            outputs_real = discriminator(real_images)\n",
    "            d_loss_real = criterion(outputs_real, real_labels)\n",
    "\n",
    "            # Fake images\n",
    "            z = torch.randn(batch_size, latent_dim, device=device)\n",
    "            fake_images = generator(z)\n",
    "            outputs_fake = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(outputs_fake, fake_labels)\n",
    "\n",
    "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Train the generator\n",
    "            optimizer_G.zero_grad()\n",
    "            outputs = discriminator(fake_images)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            d_losses.append(d_loss.item())\n",
    "            g_losses.append(g_loss.item())\n",
    "\n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}], '\n",
    "                      f'D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "\n",
    "        # Generate and save samples every epoch\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(32, latent_dim, device=device)\n",
    "            fake_samples = generator(z)\n",
    "            vutils.save_image(fake_samples, f'fake_samples_epoch_{epoch+1:02d}.png',\n",
    "                            normalize=True, nrow=8)\n",
    "            print(f'Saved samples for epoch {epoch+1}')\n",
    "\n",
    "        # Plot loss curves every 2 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.title(f\"Generator and Discriminator Loss - Epoch {epoch+1}\")\n",
    "            plt.plot(g_losses, label=\"G Loss\")\n",
    "            plt.plot(d_losses, label=\"D Loss\")\n",
    "            plt.xlabel(\"Iterations\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f'loss_plot_epoch_{epoch+1:02d}.png')\n",
    "            plt.close()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator parameters: 1,050,883\n",
      "Discriminator parameters: 395,713\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-10-18T21:50:52.959795300Z",
     "start_time": "2025-10-18T10:36:45.678721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main training loop\n",
    "print(\"Starting training...\")\n",
    "train_gan(generator, discriminator, dataloader, num_epochs=num_epochs)\n",
    "print(\"Training completed!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [1/10], Batch [20/3125], D Loss: 0.6065, G Loss: 0.9074\n",
      "Epoch [1/10], Batch [40/3125], D Loss: 0.4467, G Loss: 1.5799\n",
      "Epoch [1/10], Batch [60/3125], D Loss: 0.6644, G Loss: 1.3866\n",
      "Epoch [1/10], Batch [80/3125], D Loss: 0.5484, G Loss: 1.6885\n",
      "Epoch [1/10], Batch [100/3125], D Loss: 0.4316, G Loss: 1.6188\n",
      "Epoch [1/10], Batch [120/3125], D Loss: 0.4619, G Loss: 1.4403\n",
      "Epoch [1/10], Batch [140/3125], D Loss: 0.4939, G Loss: 1.5904\n",
      "Epoch [1/10], Batch [160/3125], D Loss: 0.6754, G Loss: 1.3510\n",
      "Epoch [1/10], Batch [180/3125], D Loss: 0.6325, G Loss: 1.1295\n",
      "Epoch [1/10], Batch [200/3125], D Loss: 0.6710, G Loss: 0.9767\n",
      "Epoch [1/10], Batch [220/3125], D Loss: 0.6282, G Loss: 0.9186\n",
      "Epoch [1/10], Batch [240/3125], D Loss: 0.7062, G Loss: 0.8775\n",
      "Epoch [1/10], Batch [260/3125], D Loss: 0.5164, G Loss: 1.0150\n",
      "Epoch [1/10], Batch [280/3125], D Loss: 0.6876, G Loss: 1.0355\n",
      "Epoch [1/10], Batch [300/3125], D Loss: 0.4625, G Loss: 1.2416\n",
      "Epoch [1/10], Batch [320/3125], D Loss: 0.6264, G Loss: 1.5687\n",
      "Epoch [1/10], Batch [340/3125], D Loss: 0.4920, G Loss: 1.3244\n",
      "Epoch [1/10], Batch [360/3125], D Loss: 0.9332, G Loss: 0.8586\n",
      "Epoch [1/10], Batch [380/3125], D Loss: 0.5728, G Loss: 1.3009\n",
      "Epoch [1/10], Batch [400/3125], D Loss: 0.7346, G Loss: 1.0703\n",
      "Epoch [1/10], Batch [420/3125], D Loss: 0.4897, G Loss: 1.1165\n",
      "Epoch [1/10], Batch [440/3125], D Loss: 0.3245, G Loss: 1.5484\n",
      "Epoch [1/10], Batch [460/3125], D Loss: 0.7641, G Loss: 1.5948\n",
      "Epoch [1/10], Batch [480/3125], D Loss: 0.5578, G Loss: 1.6815\n",
      "Epoch [1/10], Batch [500/3125], D Loss: 0.8075, G Loss: 1.0481\n",
      "Epoch [1/10], Batch [520/3125], D Loss: 0.5429, G Loss: 1.4573\n",
      "Epoch [1/10], Batch [540/3125], D Loss: 0.4037, G Loss: 1.4567\n",
      "Epoch [1/10], Batch [560/3125], D Loss: 0.6846, G Loss: 1.7063\n",
      "Epoch [1/10], Batch [580/3125], D Loss: 0.3995, G Loss: 1.7731\n",
      "Epoch [1/10], Batch [600/3125], D Loss: 0.8780, G Loss: 1.0303\n",
      "Epoch [1/10], Batch [620/3125], D Loss: 0.6927, G Loss: 1.2042\n",
      "Epoch [1/10], Batch [640/3125], D Loss: 0.6232, G Loss: 1.3019\n",
      "Epoch [1/10], Batch [660/3125], D Loss: 0.6349, G Loss: 1.3846\n",
      "Epoch [1/10], Batch [680/3125], D Loss: 0.7049, G Loss: 1.1305\n",
      "Epoch [1/10], Batch [700/3125], D Loss: 0.6343, G Loss: 0.8564\n",
      "Epoch [1/10], Batch [720/3125], D Loss: 0.7367, G Loss: 1.0620\n",
      "Epoch [1/10], Batch [740/3125], D Loss: 0.9297, G Loss: 0.9130\n",
      "Epoch [1/10], Batch [760/3125], D Loss: 0.8070, G Loss: 0.6273\n",
      "Epoch [1/10], Batch [780/3125], D Loss: 0.7273, G Loss: 0.8186\n",
      "Epoch [1/10], Batch [800/3125], D Loss: 0.8778, G Loss: 0.6787\n",
      "Epoch [1/10], Batch [820/3125], D Loss: 0.6050, G Loss: 0.8301\n",
      "Epoch [1/10], Batch [840/3125], D Loss: 0.7264, G Loss: 0.8044\n",
      "Epoch [1/10], Batch [860/3125], D Loss: 0.6012, G Loss: 0.7666\n",
      "Epoch [1/10], Batch [880/3125], D Loss: 0.7604, G Loss: 0.7402\n",
      "Epoch [1/10], Batch [900/3125], D Loss: 0.7063, G Loss: 0.8233\n",
      "Epoch [1/10], Batch [920/3125], D Loss: 0.7228, G Loss: 0.6513\n",
      "Epoch [1/10], Batch [940/3125], D Loss: 0.6226, G Loss: 0.7461\n",
      "Epoch [1/10], Batch [960/3125], D Loss: 0.7792, G Loss: 0.8056\n",
      "Epoch [1/10], Batch [980/3125], D Loss: 0.7300, G Loss: 0.6534\n",
      "Epoch [1/10], Batch [1000/3125], D Loss: 0.5973, G Loss: 1.0649\n",
      "Epoch [1/10], Batch [1020/3125], D Loss: 0.5912, G Loss: 1.0307\n",
      "Epoch [1/10], Batch [1040/3125], D Loss: 0.7386, G Loss: 0.7954\n",
      "Epoch [1/10], Batch [1060/3125], D Loss: 0.6215, G Loss: 0.9032\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

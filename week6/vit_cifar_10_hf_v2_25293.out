Requirement already satisfied: torchvision in /home/algh/.local/lib/python3.11/site-packages (0.16.2)
Requirement already satisfied: accelerate in /home/algh/.local/lib/python3.11/site-packages (0.25.0)
Requirement already satisfied: datasets in /home/algh/.local/lib/python3.11/site-packages (2.18.0)
Requirement already satisfied: transformers in /home/algh/.local/lib/python3.11/site-packages (4.36.2)
Requirement already satisfied: numpy in /opt/itu/easybuild/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from torchvision) (1.25.1)
Requirement already satisfied: requests in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torchvision) (2.31.0)
Requirement already satisfied: torch==2.1.2 in /opt/itu/easybuild/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages (from torchvision) (2.1.2)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/itu/easybuild/software/Pillow/10.0.0-GCCcore-12.3.0/lib/python3.11/site-packages (from torchvision) (10.0.0)
Requirement already satisfied: filelock in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.12.2)
Requirement already satisfied: typing-extensions in /home/algh/.local/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (4.15.0)
Requirement already satisfied: sympy in /opt/itu/easybuild/software/sympy/1.12-gfbf-2023a/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (1.12)
Requirement already satisfied: networkx in /opt/itu/easybuild/software/networkx/3.1-gfbf-2023a/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.1)
Requirement already satisfied: jinja2 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (3.1.2)
Requirement already satisfied: fsspec in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch==2.1.2->torchvision) (2023.6.0)
Requirement already satisfied: packaging>=20.0 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from accelerate) (23.1)
Requirement already satisfied: psutil in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from accelerate) (5.9.5)
Requirement already satisfied: pyyaml in /opt/itu/easybuild/software/PyYAML/6.0-GCCcore-12.3.0/lib/python3.11/site-packages (from accelerate) (6.0)
Requirement already satisfied: huggingface-hub in /home/algh/.local/lib/python3.11/site-packages (from accelerate) (0.35.3)
Requirement already satisfied: safetensors>=0.3.1 in /home/algh/.local/lib/python3.11/site-packages (from accelerate) (0.6.2)
Requirement already satisfied: pyarrow>=12.0.0 in /home/algh/.local/lib/python3.11/site-packages (from datasets) (21.0.0)
Requirement already satisfied: pyarrow-hotfix in /home/algh/.local/lib/python3.11/site-packages (from datasets) (0.7)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/algh/.local/lib/python3.11/site-packages (from datasets) (0.3.8)
Requirement already satisfied: pandas in /opt/itu/easybuild/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from datasets) (2.0.3)
Requirement already satisfied: tqdm>=4.62.1 in /home/algh/.local/lib/python3.11/site-packages (from datasets) (4.67.1)
Requirement already satisfied: xxhash in /home/algh/.local/lib/python3.11/site-packages (from datasets) (3.6.0)
Requirement already satisfied: multiprocess in /home/algh/.local/lib/python3.11/site-packages (from datasets) (0.70.16)
Requirement already satisfied: aiohttp in /home/algh/.local/lib/python3.11/site-packages (from datasets) (3.12.15)
Requirement already satisfied: regex!=2019.12.17 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers) (2023.6.3)
Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/algh/.local/lib/python3.11/site-packages (from transformers) (0.15.2)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/algh/.local/lib/python3.11/site-packages (from huggingface-hub->accelerate) (1.1.10)
Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/algh/.local/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)
Requirement already satisfied: aiosignal>=1.4.0 in /home/algh/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)
Requirement already satisfied: attrs>=17.3.0 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)
Requirement already satisfied: frozenlist>=1.1.1 in /home/algh/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.7.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /home/algh/.local/lib/python3.11/site-packages (from aiohttp->datasets) (6.6.4)
Requirement already satisfied: propcache>=0.2.0 in /home/algh/.local/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.2)
Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/algh/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.20.1)
Requirement already satisfied: idna>=2.0 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.4)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->torchvision) (3.1.0)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->torchvision) (1.26.16)
Requirement already satisfied: certifi>=2017.4.17 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->torchvision) (2023.5.7)
Requirement already satisfied: MarkupSafe>=2.0 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jinja2->torch==2.1.2->torchvision) (2.1.3)
Requirement already satisfied: python-dateutil>=2.8.2 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from pandas->datasets) (2023.3)
Requirement already satisfied: tzdata>=2022.1 in /opt/itu/easybuild/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from pandas->datasets) (2023.3)
Requirement already satisfied: six>=1.5 in /opt/itu/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)
Requirement already satisfied: mpmath>=0.19 in /opt/itu/easybuild/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from sympy->torch==2.1.2->torchvision) (1.3.0)
Loading CIFAR-10 dataset...
Train: 45000 | Val: 5000 | Test: 10000
Testing dataset...
Sample keys: ['pixel_values', 'labels']
Pixel values shape: torch.Size([3, 224, 224])
Label: tensor(4)

Loading pretrained ViT model...
Backbone frozen. Only classifier layer will be fine-tuned.
Trainable parameters: 7,690/85,806,346 (0.01%)

Training pretrained ViT (fine-tuning)...
{'loss': 1.4277072847909695e+19, 'learning_rate': 4.928647877274349e-06, 'epoch': 0.18}
{'loss': 1.4403137608679051e+19, 'learning_rate': 4.8394577238672856e-06, 'epoch': 0.36}
{'loss': 1.4556336557203313e+19, 'learning_rate': 4.750267570460222e-06, 'epoch': 0.53}
{'loss': 1.4507135857174196e+19, 'learning_rate': 4.661077417053157e-06, 'epoch': 0.71}
{'loss': 1.4188373327348728e+19, 'learning_rate': 4.571887263646093e-06, 'epoch': 0.89}
{'eval_loss': 1.4037979523257991e+19, 'eval_accuracy': 0.4374, 'eval_runtime': 38.3008, 'eval_samples_per_second': 130.546, 'eval_steps_per_second': 8.172, 'epoch': 1.0}
{'loss': 1.4608795611562832e+19, 'learning_rate': 4.4826971102390295e-06, 'epoch': 1.07}
{'loss': 1.4586860829577724e+19, 'learning_rate': 4.393506956831966e-06, 'epoch': 1.24}
{'loss': 1.4302080210740578e+19, 'learning_rate': 4.304316803424902e-06, 'epoch': 1.42}
{'loss': 1.4216498307021656e+19, 'learning_rate': 4.215126650017838e-06, 'epoch': 1.6}
{'loss': 1.4327445609741834e+19, 'learning_rate': 4.125936496610774e-06, 'epoch': 1.78}
{'loss': 1.4244401484412936e+19, 'learning_rate': 4.0367463432037105e-06, 'epoch': 1.96}
{'eval_loss': 1.4033592471863165e+19, 'eval_accuracy': 0.565, 'eval_runtime': 38.3131, 'eval_samples_per_second': 130.504, 'eval_steps_per_second': 8.17, 'epoch': 2.0}
{'loss': 1.4478041477681478e+19, 'learning_rate': 3.947556189796647e-06, 'epoch': 2.13}
{'loss': 1.4085610191051387e+19, 'learning_rate': 3.858366036389583e-06, 'epoch': 2.31}
{'loss': 1.4950060376926458e+19, 'learning_rate': 3.769175882982519e-06, 'epoch': 2.49}
{'loss': 1.4305262003877315e+19, 'learning_rate': 3.6799857295754553e-06, 'epoch': 2.67}
{'loss': 1.4139724318273964e+19, 'learning_rate': 3.590795576168391e-06, 'epoch': 2.84}
{'eval_loss': 1.4029208719003222e+19, 'eval_accuracy': 0.5948, 'eval_runtime': 38.5117, 'eval_samples_per_second': 129.831, 'eval_steps_per_second': 8.127, 'epoch': 3.0}
{'loss': 1.4626808884172407e+19, 'learning_rate': 3.5016054227613272e-06, 'epoch': 3.02}
{'loss': 1.4515502419381944e+19, 'learning_rate': 3.4124152693542634e-06, 'epoch': 3.2}
{'loss': 1.4487129741729511e+19, 'learning_rate': 3.3232251159471996e-06, 'epoch': 3.38}
{'loss': 1.4100517105817983e+19, 'learning_rate': 3.234034962540136e-06, 'epoch': 3.55}
{'loss': 1.461872717464109e+19, 'learning_rate': 3.144844809133072e-06, 'epoch': 3.73}
{'loss': 1.4329670387957756e+19, 'learning_rate': 3.055654655726008e-06, 'epoch': 3.91}
{'eval_loss': 1.402482496614328e+19, 'eval_accuracy': 0.6082, 'eval_runtime': 38.3391, 'eval_samples_per_second': 130.415, 'eval_steps_per_second': 8.164, 'epoch': 4.0}
{'loss': 1.4125403997358834e+19, 'learning_rate': 2.9664645023189444e-06, 'epoch': 4.09}
{'loss': 1.4528749757685854e+19, 'learning_rate': 2.8772743489118806e-06, 'epoch': 4.27}
{'loss': 1.4288027854003274e+19, 'learning_rate': 2.7880841955048164e-06, 'epoch': 4.44}
{'loss': 1.449578115661369e+19, 'learning_rate': 2.6988940420977526e-06, 'epoch': 4.62}
{'loss': 1.451562514247179e+19, 'learning_rate': 2.6097038886906888e-06, 'epoch': 4.8}
{'loss': 1.4484354398459144e+19, 'learning_rate': 2.520513735283625e-06, 'epoch': 4.98}
{'eval_loss': 1.4024559983840985e+19, 'eval_accuracy': 0.6114, 'eval_runtime': 38.4653, 'eval_samples_per_second': 129.987, 'eval_steps_per_second': 8.137, 'epoch': 5.0}
{'loss': 1.434068731854621e+19, 'learning_rate': 2.431323581876561e-06, 'epoch': 5.15}
{'loss': 1.4274057687959171e+19, 'learning_rate': 2.3421334284694974e-06, 'epoch': 5.33}
{'loss': 1.4410203756494395e+19, 'learning_rate': 2.252943275062433e-06, 'epoch': 5.51}
{'loss': 1.4609287629822122e+19, 'learning_rate': 2.1637531216553693e-06, 'epoch': 5.69}
{'loss': 1.4399982837140079e+19, 'learning_rate': 2.0745629682483055e-06, 'epoch': 5.87}
{'eval_loss': 1.4024559983840985e+19, 'eval_accuracy': 0.6162, 'eval_runtime': 38.4204, 'eval_samples_per_second': 130.139, 'eval_steps_per_second': 8.147, 'epoch': 6.0}
{'loss': 1.3985133757464844e+19, 'learning_rate': 1.9853728148412417e-06, 'epoch': 6.04}
{'loss': 1.455940801214918e+19, 'learning_rate': 1.8961826614341777e-06, 'epoch': 6.22}
{'loss': 1.4468959969032884e+19, 'learning_rate': 1.806992508027114e-06, 'epoch': 6.4}
{'loss': 1.429839176264576e+19, 'learning_rate': 1.71780235462005e-06, 'epoch': 6.58}
{'loss': 1.4727529638038735e+19, 'learning_rate': 1.6286122012129863e-06, 'epoch': 6.75}
{'loss': 1.39386430985115e+19, 'learning_rate': 1.5394220478059225e-06, 'epoch': 6.93}
{'eval_loss': 1.4024559983840985e+19, 'eval_accuracy': 0.6188, 'eval_runtime': 38.3109, 'eval_samples_per_second': 130.511, 'eval_steps_per_second': 8.17, 'epoch': 7.0}
{'loss': 1.4372900440780886e+19, 'learning_rate': 1.4502318943988587e-06, 'epoch': 7.11}
{'loss': 1.4302645412493812e+19, 'learning_rate': 1.3610417409917945e-06, 'epoch': 7.29}
{'loss': 1.4312204302702905e+19, 'learning_rate': 1.2718515875847306e-06, 'epoch': 7.47}
{'loss': 1.4244655937791883e+19, 'learning_rate': 1.1826614341776668e-06, 'epoch': 7.64}
{'loss': 1.471041821125454e+19, 'learning_rate': 1.093471280770603e-06, 'epoch': 7.82}
{'loss': 1.4423882314462626e+19, 'learning_rate': 1.0042811273635392e-06, 'epoch': 8.0}
{'eval_loss': 1.4024559983840985e+19, 'eval_accuracy': 0.62, 'eval_runtime': 38.387, 'eval_samples_per_second': 130.253, 'eval_steps_per_second': 8.154, 'epoch': 8.0}
{'loss': 1.4314664393999358e+19, 'learning_rate': 9.150909739564753e-07, 'epoch': 8.18}
{'loss': 1.4643972102352314e+19, 'learning_rate': 8.259008205494114e-07, 'epoch': 8.35}
{'loss': 1.4091529046861658e+19, 'learning_rate': 7.367106671423475e-07, 'epoch': 8.53}
{'loss': 1.477754661550031e+19, 'learning_rate': 6.475205137352837e-07, 'epoch': 8.71}
{'loss': 1.4549000193410327e+19, 'learning_rate': 5.583303603282198e-07, 'epoch': 8.89}
{'eval_loss': 1.4024559983840985e+19, 'eval_accuracy': 0.6202, 'eval_runtime': 38.32, 'eval_samples_per_second': 130.48, 'eval_steps_per_second': 8.168, 'epoch': 9.0}
{'loss': 1.3794939989801548e+19, 'learning_rate': 4.6914020692115594e-07, 'epoch': 9.07}
{'loss': 1.410883412842983e+19, 'learning_rate': 3.799500535140921e-07, 'epoch': 9.24}
{'loss': 1.4886783676261997e+19, 'learning_rate': 2.907599001070282e-07, 'epoch': 9.42}
{'loss': 1.4534587548702835e+19, 'learning_rate': 2.0156974669996431e-07, 'epoch': 9.6}
{'loss': 1.4494678900604891e+19, 'learning_rate': 1.1237959329290048e-07, 'epoch': 9.78}
{'loss': 1.4271710186653405e+19, 'learning_rate': 2.3189439885836603e-08, 'epoch': 9.95}
{'eval_loss': 1.4024559983840985e+19, 'eval_accuracy': 0.6206, 'eval_runtime': 38.3068, 'eval_samples_per_second': 130.525, 'eval_steps_per_second': 8.171, 'epoch': 10.0}
{'train_runtime': 3958.65, 'train_samples_per_second': 113.675, 'train_steps_per_second': 7.106, 'train_loss': 1.4391485519048962e+19, 'epoch': 10.0}

Pretrained model test accuracy: 0.6059

Training ViT from scratch for comparison...
{'loss': 2.2031, 'learning_rate': 0.00019644507643085674, 'epoch': 0.18}
{'loss': 2.1533, 'learning_rate': 0.00019289015286171347, 'epoch': 0.36}
{'loss': 2.1258, 'learning_rate': 0.0001893352292925702, 'epoch': 0.53}
{'loss': 2.1076, 'learning_rate': 0.00018578030572342696, 'epoch': 0.71}
{'loss': 2.1017, 'learning_rate': 0.0001822253821542837, 'epoch': 0.89}
{'eval_loss': 2.0857245922088623, 'eval_accuracy': 0.1888, 'eval_runtime': 38.2489, 'eval_samples_per_second': 130.723, 'eval_steps_per_second': 8.183, 'epoch': 1.0}
{'loss': 2.084, 'learning_rate': 0.00017867045858514042, 'epoch': 1.07}
{'loss': 2.0704, 'learning_rate': 0.00017511553501599716, 'epoch': 1.24}
{'loss': 2.0596, 'learning_rate': 0.0001715606114468539, 'epoch': 1.42}
{'loss': 2.054, 'learning_rate': 0.00016800568787771062, 'epoch': 1.6}
{'loss': 2.0373, 'learning_rate': 0.00016445076430856738, 'epoch': 1.78}
{'loss': 2.0213, 'learning_rate': 0.0001608958407394241, 'epoch': 1.96}
{'eval_loss': 1.9805347919464111, 'eval_accuracy': 0.2492, 'eval_runtime': 38.163, 'eval_samples_per_second': 131.017, 'eval_steps_per_second': 8.202, 'epoch': 2.0}
{'loss': 2.0043, 'learning_rate': 0.00015734091717028087, 'epoch': 2.13}
{'loss': 1.9938, 'learning_rate': 0.0001537859936011376, 'epoch': 2.31}
{'loss': 1.9752, 'learning_rate': 0.00015023107003199433, 'epoch': 2.49}
{'loss': 1.9444, 'learning_rate': 0.00014667614646285106, 'epoch': 2.67}
{'loss': 1.928, 'learning_rate': 0.0001431212228937078, 'epoch': 2.84}
{'eval_loss': 1.9199867248535156, 'eval_accuracy': 0.2684, 'eval_runtime': 38.3167, 'eval_samples_per_second': 130.491, 'eval_steps_per_second': 8.169, 'epoch': 3.0}
{'loss': 1.9263, 'learning_rate': 0.00013956629932456452, 'epoch': 3.02}
{'loss': 1.9156, 'learning_rate': 0.00013601137575542125, 'epoch': 3.2}
{'loss': 1.9042, 'learning_rate': 0.000132456452186278, 'epoch': 3.38}
{'loss': 1.892, 'learning_rate': 0.00012890152861713474, 'epoch': 3.55}
{'loss': 1.8651, 'learning_rate': 0.00012534660504799147, 'epoch': 3.73}
{'loss': 1.8646, 'learning_rate': 0.0001217916814788482, 'epoch': 3.91}
{'eval_loss': 1.85478675365448, 'eval_accuracy': 0.3066, 'eval_runtime': 38.2746, 'eval_samples_per_second': 130.635, 'eval_steps_per_second': 8.178, 'epoch': 4.0}
{'loss': 1.8459, 'learning_rate': 0.00011823675790970494, 'epoch': 4.09}
{'loss': 1.8244, 'learning_rate': 0.00011468183434056168, 'epoch': 4.27}
{'loss': 1.81, 'learning_rate': 0.00011112691077141841, 'epoch': 4.44}
{'loss': 1.8065, 'learning_rate': 0.00010757198720227514, 'epoch': 4.62}
{'loss': 1.796, 'learning_rate': 0.00010401706363313189, 'epoch': 4.8}
{'loss': 1.8046, 'learning_rate': 0.00010046214006398862, 'epoch': 4.98}
{'eval_loss': 1.768364667892456, 'eval_accuracy': 0.331, 'eval_runtime': 38.3309, 'eval_samples_per_second': 130.443, 'eval_steps_per_second': 8.166, 'epoch': 5.0}
{'loss': 1.7656, 'learning_rate': 9.690721649484537e-05, 'epoch': 5.15}
{'loss': 1.7667, 'learning_rate': 9.33522929257021e-05, 'epoch': 5.33}
{'loss': 1.7592, 'learning_rate': 8.979736935655884e-05, 'epoch': 5.51}
{'loss': 1.7333, 'learning_rate': 8.624244578741557e-05, 'epoch': 5.69}
{'loss': 1.7307, 'learning_rate': 8.26875222182723e-05, 'epoch': 5.87}
{'eval_loss': 1.7433929443359375, 'eval_accuracy': 0.3548, 'eval_runtime': 38.2205, 'eval_samples_per_second': 130.82, 'eval_steps_per_second': 8.189, 'epoch': 6.0}
{'loss': 1.7331, 'learning_rate': 7.913259864912905e-05, 'epoch': 6.04}
{'loss': 1.7081, 'learning_rate': 7.55776750799858e-05, 'epoch': 6.22}
{'loss': 1.6933, 'learning_rate': 7.202275151084252e-05, 'epoch': 6.4}
{'loss': 1.7153, 'learning_rate': 6.846782794169926e-05, 'epoch': 6.58}
{'loss': 1.6841, 'learning_rate': 6.491290437255599e-05, 'epoch': 6.75}
{'loss': 1.6767, 'learning_rate': 6.135798080341273e-05, 'epoch': 6.93}
{'eval_loss': 1.7091574668884277, 'eval_accuracy': 0.369, 'eval_runtime': 38.229, 'eval_samples_per_second': 130.791, 'eval_steps_per_second': 8.188, 'epoch': 7.0}
{'loss': 1.6683, 'learning_rate': 5.7803057234269463e-05, 'epoch': 7.11}
{'loss': 1.6806, 'learning_rate': 5.42481336651262e-05, 'epoch': 7.29}
{'loss': 1.6339, 'learning_rate': 5.069321009598293e-05, 'epoch': 7.47}
{'loss': 1.6458, 'learning_rate': 4.713828652683968e-05, 'epoch': 7.64}
{'loss': 1.6259, 'learning_rate': 4.358336295769641e-05, 'epoch': 7.82}
{'loss': 1.6175, 'learning_rate': 4.002843938855315e-05, 'epoch': 8.0}
{'eval_loss': 1.6334128379821777, 'eval_accuracy': 0.4014, 'eval_runtime': 38.2942, 'eval_samples_per_second': 130.568, 'eval_steps_per_second': 8.174, 'epoch': 8.0}
{'loss': 1.5929, 'learning_rate': 3.6473515819409885e-05, 'epoch': 8.18}
{'loss': 1.5985, 'learning_rate': 3.291859225026662e-05, 'epoch': 8.35}
{'loss': 1.5857, 'learning_rate': 2.9363668681123358e-05, 'epoch': 8.53}
{'loss': 1.5899, 'learning_rate': 2.5808745111980092e-05, 'epoch': 8.71}
{'loss': 1.5756, 'learning_rate': 2.225382154283683e-05, 'epoch': 8.89}
{'eval_loss': 1.6023766994476318, 'eval_accuracy': 0.4174, 'eval_runtime': 37.7178, 'eval_samples_per_second': 132.563, 'eval_steps_per_second': 8.298, 'epoch': 9.0}
{'loss': 1.5687, 'learning_rate': 1.8698897973693565e-05, 'epoch': 9.07}
{'loss': 1.5542, 'learning_rate': 1.5143974404550305e-05, 'epoch': 9.24}
{'loss': 1.5336, 'learning_rate': 1.158905083540704e-05, 'epoch': 9.42}
{'loss': 1.5426, 'learning_rate': 8.034127266263776e-06, 'epoch': 9.6}
{'loss': 1.5425, 'learning_rate': 4.479203697120512e-06, 'epoch': 9.78}
{'loss': 1.5248, 'learning_rate': 9.242801279772485e-07, 'epoch': 9.95}
{'eval_loss': 1.5686233043670654, 'eval_accuracy': 0.434, 'eval_runtime': 37.6055, 'eval_samples_per_second': 132.959, 'eval_steps_per_second': 8.323, 'epoch': 10.0}
{'train_runtime': 7293.9116, 'train_samples_per_second': 61.695, 'train_steps_per_second': 3.857, 'train_loss': 1.8053591470891286, 'epoch': 10.0}

Scratch model test accuracy: 0.4277

Generating comparison plot...
Generating attention visualization...
Attention visualization failed: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor

========== SUMMARY ==========
Fine-tuned ViT accuracy: 0.6059
Scratch ViT accuracy:    0.4277
=============================
All results and plots saved in current directory.
